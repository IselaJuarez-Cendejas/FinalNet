{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9JrXXOoBp9U",
        "outputId": "4cd8cfe2-f4a9-4683-d6e5-74d14b5c3794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "FinalNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv7): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv8): Conv2d(2048, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn8): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "  (bn9): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (bn10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time # check the processing overhead\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class FinalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FinalNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, 1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3, 1, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(1024)\n",
        "        self.conv7 = nn.Conv2d(1024, 2048, 3, 1, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(2048)\n",
        "        self.conv8 = nn.Conv2d(2048, 4096, 3, 1, padding=1)\n",
        "        self.bn8 = nn.BatchNorm2d(4096)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(4096, 2048)\n",
        "        self.bn9 = nn.BatchNorm1d(2048)\n",
        "        self.fc2 = nn.Linear(2048, 1024)\n",
        "        self.bn10 = nn.BatchNorm1d(1024)\n",
        "        self.fc3 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.bn7(self.conv7(x)))\n",
        "        x = F.relu(self.bn8(self.conv8(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.bn9(self.fc1(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.bn10(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "model = FinalNet().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLJ2tXDmpzqN"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "num_epochs = 50\n",
        "learning_rate = 0.05\n",
        "\n",
        "# Training Data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Testing Data preparation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize the model\n",
        "model = FinalNet().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print training loss and accuracy for each epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss/(batch_idx+1):.3f} - Accuracy: {100.0*correct/total:.2f}%\")\n",
        "\n",
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss/(batch_idx+1):.3f} - Accuracy: {100.0*correct/total:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}